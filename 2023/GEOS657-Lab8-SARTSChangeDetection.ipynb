{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"NotebookAddons/blackboard-banner.png\" width=\"100%\" />\n",
    "<font face=\"Calibri\">\n",
    "<br>\n",
    "<font size=\"7\"> <b> GEOS 657: Microwave Remote Sensing<b> </font>\n",
    "\n",
    "<font size=\"5\"> <b>Lab 8: Change Detection in SAR Amplitude Time Series Data <font color='rgba(200,0,0,0.2)'> -- [20 Points] </font> </b> </font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer; University of Alaska Fairbanks & Josef Kellndorfer, <a href=\"http://earthbigdata.com/\" target=\"_blank\">Earth Big Data, LLC</a> </b> <br>\n",
    "<img style=\"padding: 7px\" src=\"NotebookAddons/UAFLogo_A_647.png\" width=\"170\" align=\"right\" /><font color='rgba(200,0,0,0.2)'> <b>Due Date: </b> April 22, 2021 </font>\n",
    "</font>\n",
    "\n",
    "<font size=\"3\"> This Lab is part of the UAF course <a href=\"https://radar.community.uaf.edu/\" target=\"_blank\">GEOS 657: Microwave Remote Sensing</a>. It is introducing you to the methods of change detection in deep multi-temporal SAR image data stacks. Specifically, the lab applies the method of <i>Cumulative Sums</i> to perform change detection in a 60 image deep Sentinel-1 data stack over Niamey, Niger.  \n",
    "\n",
    "As previously, the work will be done within the framework of a Jupyter Notebook. <br>\n",
    "\n",
    "<b>In this chapter we introduce the following data analysis concepts:</b>\n",
    "\n",
    "- The concepts of time series slicing by month, year, and date.\n",
    "- The concepts and workflow of Cumulative Sum-based change point detection.\n",
    "- The identification of change dates for each identified change point.\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font face=\"Calibri\" size=\"4\"> <font color='rgba(200,0,0,0.2)'> <b>THIS NOTEBOOK INCLUDES FOUR HOMEWORK ASSIGNMENTS.</b></font> \n",
    "<br> \n",
    "<font size=\"3\"> Complete all assignments to achieve full score. </font> <br>\n",
    "\n",
    "<font size=\"3\"> To submit your homework, please download your completed Jupyter Notebook from the server both asf PDF (*.pdf) and Notebook file (*.ipynb) and submit them as a ZIP bundle via the GEOS 657 Blackboard page. To download, please select the following options in the main menu of the notebook interface:\n",
    "\n",
    "<ol type=\"1\">\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b> Save your notebook with all of its content</b></font> by selecting <i> File / Save and Checkpoint </i> </li>\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b>To export in Notebook format</b></font>, click the <i>radio button next to the notebook file in the main Jupyter Hub browser tab. Once clicked, a download field will appear near the top of the page.</i></li>\n",
    "  <li><font color='rgba(200,0,0,0.2)'> <b>To export in PDF format</b></font>, right-click on your browser window and print the browser content to PDF</li>\n",
    "</ol>\n",
    "\n",
    "Contact me at fjmeyer@alaska.edu should you run into any problems.\n",
    "</font>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font face=\"Calibri\" size=\"5\" color=\"darkred\"> <b>Important Note about JupyterHub</b> </font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> Your JupyterHub server will automatically shutdown when left idle for more than 1 hour. Your notebooks will not be lost but you will have to restart their kernels and re-run them from the beginning. You will not be able to seamlessly continue running a partially run notebook. </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import url_widget as url_w\n",
    "notebookUrl = url_w.URLWidget()\n",
    "display(notebookUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "notebookUrl = notebookUrl.value\n",
    "user = !echo $JUPYTERHUB_USER\n",
    "env = !echo $CONDA_PREFIX\n",
    "if env[0] == '':\n",
    "    env[0] = 'Python 3 (base)'\n",
    "if env[0] != '/home/jovyan/.local/envs/rtc_analysis':\n",
    "    display(Markdown(f'<text style=color:red><strong>WARNING:</strong></text>'))\n",
    "    display(Markdown(f'<text style=color:red>This notebook should be run using the \"rtc_analysis\" conda environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>It is currently using the \"{env[0].split(\"/\")[-1]}\" environment.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Select the \"rtc_analysis\" from the \"Change Kernel\" submenu of the \"Kernel\" menu.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>If the \"rtc_analysis\" environment is not present, use <a href=\"{notebookUrl.split(\"/user\")[0]}/user/{user[0]}/notebooks/conda_environments/Create_OSL_Conda_Environments.ipynb\"> Create_OSL_Conda_Environments.ipynb </a> to create it.</text>'))\n",
    "    display(Markdown(f'<text style=color:red>Note that you must restart your server after creating a new environment before it is usable by notebooks.</text>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0. Importing Relevant Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\">\n",
    "<font size=\"3\"> The first step of this lab exercise on SAR image time series analysis and change detection is to <b>import the necessary python libraries into your Jupyter Notebook.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import gdal # for Info\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "asfn.jupytertheme_matplotlib_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1. Load Data Stack for this Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\"> \n",
    "<font size=\"3\"> <img style=\"padding: 7px\" src=\"NotebookAddons/Lab8-Agrhymet.JPG\" width=\"400\" align=\"right\" />This Lab will use a 60-image deep C-band Sentinel-1 SAR data stack over Niamey, Niger to demonstrate the concepts of time series change detection. The data are available to us through the services of the <a href=\"https://www.asf.alaska.edu/\" target=\"_blank\">Alaska Satellite Facility</a>. \n",
    "\n",
    "Specifically we will use a small image segment over the campus of <a href=\"http://www.agrhymet.ne/eng/\" target=\"_blank\">AGRHYMET Regional Centre</a>, a regional organization supporting West Africa in the use or remote sensing.  \n",
    "\n",
    "This site was picked as we had information about construction going on at this site sometime in the 2015 - 2017 time frame. Land was cleared and a building was erected. In this exercise we will see if we can detect the construction activity and if we are able to determine when construction began and when it ended.\n",
    "\n",
    "In this case, we will <b>retrieve the relevant data</b> from an <a href=\"https://aws.amazon.com/\" target=\"_blank\">Amazon Web Service (AWS)</a> cloud storage bucket.</font></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.1. Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Before we download anything, <b>create a working directory for this analysis and change into it:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = f\"{os.getcwd()}/lab_8_data\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "os.chdir(path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Download the data from the AWS bucket, unzip and clean up after yourself:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!aws --region=us-west-2 --no-sign-request s3 cp s3://asf-jupyter-data-west/Niamey.zip Niamey.zip\n",
    "f = \"Niamey.zip\"\n",
    "asfn.asf_unzip(path, f)\n",
    "if os.path.exists(f):\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.2 Switch to the Data Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The following lines set variables that capture path variables needed for data processing. <b>Change into the unzipped /cra directory and define variables for names of the files containing data and image information:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cra_path = f\"{path}/cra/\"\n",
    "if os.path.exists(cra_path):\n",
    "    os.chdir(cra_path)\n",
    "date_file = \"S32631X402380Y1491460sS1_A_vv_0001_A_mtfil.dates\"\n",
    "image_file = \"S32631X402380Y1491460sS1_A_vv_0001_A_mtfil.vrt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.3 Assess Image Acquisition Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Before we start analyzing the available image data, we want to examine the content of our data stack. <b>To do so, we read the image acquisition dates for all files in the time series and create a *pandas* date index:</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(date_file, 'r') as d:\n",
    "    dates = d.readlines()\n",
    "time_index = pd.DatetimeIndex(dates)\n",
    "j = 1\n",
    "print('Bands and dates for', image_file)\n",
    "for i in time_index:\n",
    "    print(\"{:4d} {}\".format(j, i.date()), end=' ')\n",
    "    j += 1\n",
    "    if j%5 == 1: print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.4 Read Data In the Data Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> We Read in the time series raster stack from the entire data set. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raster_stack = gdal.Open(image_file).ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.5 Lay the Groundwork for Saving Plots and Level-3 Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a directory in which store our output, and move into it:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "product_path = 'plots_and_products'\n",
    "if not os.path.exists(product_path):\n",
    "    os.makedirs(product_path)\n",
    "if os.path.exists(product_path) and os.getcwd() != f\"{path}/{product_path}\":\n",
    "    os.chdir(product_path)\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">We will need the upper-left and lower-right corner coordinates when saving our products as GeoTiffs. In this situation, you have been given a pre-subset vrt image stack. \n",
    "<br><br>\n",
    "<b>Retrieve the corner coordinates from the vrt using gdal.Info():</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vrt = gdal.Open(f\"{cra_path}{image_file}\")\n",
    "vrt_info = gdal.Info(vrt, format='json')\n",
    "coords = [vrt_info['cornerCoordinates']['upperLeft'], vrt_info['cornerCoordinates']['lowerRight']]\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Retrieve the utm zone from the vrt:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "utm_zone = vrt_info['coordinateSystem']['wkt'].split(',')[-1][0:-2]\n",
    "print(f\"utm zone: {utm_zone}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to convert our plots into GeoTiffs:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# do not include a file extension in out_filename\n",
    "# extent must be in the form of a list: [[upper_left_x, upper_left_y], [lower_right_x, lower_right_y]]\n",
    "def geotiff_from_plot(source_image, out_filename, extent, utm_zone, cmap=None, vmin=None, vmax=None, interpolation=None, dpi=300):\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(source_image, cmap=cmap, vmin=vmin, vmax=vmax, interpolation=interpolation)\n",
    "    temp = f\"{out_filename}_temp.png\"\n",
    "    plt.savefig(temp, dpi=dpi, transparent='true', bbox_inches='tight', pad_inches=0)\n",
    "    os.environ[\"PROJ_LIB\"] = '/opt/conda/share/proj/'\n",
    "\n",
    "    cmd = f\"gdal_translate -of Gtiff -a_ullr {extent[0][0]} {extent[0][1]} {extent[1][0]} {extent[1][1]} -a_srs EPSG:{utm_zone} {temp} {out_filename}.tiff\"\n",
    "    !{cmd}\n",
    "    try:\n",
    "        os.remove(temp)\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2. Plot the Global Means of the Time Series --- <font color='rgba(200,0,0,0.2)'> [Assignment Inside]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> To accomplish this task, <b>complete the following steps:</b>\n",
    "<ol>\n",
    "    <li>Conversion to power-scale</li>\n",
    "    <li>Compute mean values</li>\n",
    "    <li>Convert to dB-scale</li>\n",
    "    <li>Create time series of means using Pandas</li>\n",
    "    <li>Plot time series of means</li>\n",
    "</ol>\n",
    "</font> \n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Convert to Power-scale:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "caldB = -83\n",
    "calPwr = np.power(10.0, caldB/10.0)\n",
    "raster_stack_pwr = np.power(raster_stack, 2.0) * calPwr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Compute means:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs_means_pwr = np.mean(raster_stack_pwr, axis=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Convert to dB-scale:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs_means_dB = 10.0 * np.log10(rs_means_pwr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Make a pandas time series object:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = pd.Series(rs_means_dB,index=time_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Use pandas to plot the time series object with band numbers as data point labels. Save the plot as a png (time_series_means.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(f\"Time Series of Means\")\n",
    "ts.plot()\n",
    "xl = plt.xlabel('Date')\n",
    "yl = plt.ylabel('$\\overline{\\gamma^o}$ [dB]')\n",
    "for xyb in zip(ts.index, rs_means_dB, range(1, len(ts)+1)):\n",
    "    plt.annotate(xyb[2], xy=xyb[0:2])\n",
    "plt.grid()\n",
    "plt.savefig('time_series_means.png', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<br>\n",
    "<hr>\n",
    "<div class=\"alert alert-danger\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>ASSIGNMENT #1</u>:  </font> Analyze Global Means Time Series Plot</b> <font color='rgba(200,0,0,0.2)'> -- [3 Points] </font> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Look at the global means time series plot above and determine from the <i>time_index</i> array at which dates you see  maximum and minimum values. Are relative peaks associated with seasons?\n",
    "<br><br>\n",
    "PROVIDE ANSWER HERE:\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3. Generate Time Series for Point Locations or Subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> In python, we can use the matrix slicing tools (Like Matlab) to obtain subsets of the data. For example to pick one pixel at a line/pixel location and obtain all band values, use:\n",
    "\n",
    ">  [:,line,pixel] notation. \n",
    "\n",
    "Or, if we are interested in a subset at a offset location we can use:\n",
    "\n",
    "> [:,yoffset:(yoffset+yrange),xoffset:(xoffset+xrange)]\n",
    "\n",
    "In the section below we will generate time series plots for point locations (pixels) or areas (e.g. a 5x5 window region). To show  individual bands, we define a <i>show_image</i> function which incorporates the matrix slicing from above.\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.1 Plotting Time Series for Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function to plot the calibrated time series for a pre-defined subset:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preconditions:\n",
    "# raster_stack must be a stack of images in SAR power units\n",
    "# time_index must be a pandas date-time index\n",
    "# band_number must represent a valid bandnumber in the raster_stack\n",
    "def show_image(raster_stack, time_index, band_number, output_filename=None, subset=None, vmin=None, vmax=None):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    \n",
    "    # If vmin or vmax are None we use percentiles as limits:\n",
    "    if vmin == None:\n",
    "        vmin = np.percentile(raster_stack[band_number-1].flatten(), 5)\n",
    "    if vmax == None:\n",
    "        vmax = np.percentile(raster_stack[band_number-1].flatten(), 95)\n",
    "\n",
    "    ax1.imshow(raster_stack[band_number-1], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title('Image Band {} {}'.format(band_number, time_index[band_number-1].date()))\n",
    "    if subset == None:\n",
    "        bands, ydim, xdim = raster_stack.shape\n",
    "        subset = (0, 0, xdim, ydim)\n",
    "        \n",
    "    ax1.add_patch(patches.Rectangle((subset[0], subset[1]), subset[2], subset[3], fill=False, edgecolor='red'))\n",
    "    ax1.xaxis.set_label_text('Pixel')\n",
    "    ax1.yaxis.set_label_text('Line')\n",
    "    \n",
    "    ts_pwr = np.mean(raster_stack[:, subset[1]:(subset[1]+subset[3]), subset[0]:(subset[0]+subset[2])], axis=(1,2))\n",
    "    ts_dB = 10.0 * np.log10(ts_pwr)\n",
    "    ax2.plot(time_index, ts_dB)\n",
    "    ax2.yaxis.set_label_text('$\\gamma^o$ [dB]')\n",
    "    ax2.set_title('$\\gamma^o$ Backscatter Time Series')\n",
    "    # Add a vertical line for the date where the image is displayed\n",
    "    ax2.axvline(time_index[band_number-1], color='red')\n",
    "    plt.grid()\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    if output_filename:\n",
    "        plt.savefig(output_filename, dpi=72)\n",
    "        print(f\"Saved plot: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">Call show_image() on different bands to compare the information content of different time steps in our area of interest.\n",
    "<br><br>\n",
    " <b>Call show_image() on band number 24:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "band_number = 24 \n",
    "subset = [5, 20, 3, 3]\n",
    "show_image(raster_stack_pwr, time_index, band_number, subset=subset, output_filename=f\"band_{band_number}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Call show_image() on band number 43:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "band_number = 43\n",
    "show_image(raster_stack_pwr, time_index, band_number, subset=subset, output_filename=f\"band_{band_number}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 3.2 Generate a Time Series Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Write a function that creates an object representing the time series for an image subset:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract the means along the time series axes\n",
    "# raster shape is time steps, lines, pixels. \n",
    "# With axis=1,2, we average lines and pixels for each time step (axis 0)\n",
    "# returns pandas time series object\n",
    "def timeSeries(raster_stack_pwr, time_index, subset, ndv=0.0):\n",
    "    raster = raster_stack_pwr.copy()\n",
    "    if ndv != np.nan:\n",
    "        raster[np.equal(raster, ndv)] = np.nan\n",
    "    ts_pwr = np.nanmean(raster[:,subset[1]:(subset[1]+subset[3]), subset[0]:(subset[0]+subset[2])], axis=(1, 2))\n",
    "    # convert the means to dB\n",
    "    ts_dB = 10.0 * np.log10(ts_pwr)\n",
    "    # make the pandas time series object\n",
    "    ts = pd.Series(ts_dB, index=time_index)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Call timeSeries() to make a time series object for the chosen subset:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = timeSeries(raster_stack_pwr, time_index, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the time series object:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = ts.plot(figsize=(16, 4))\n",
    "fig.yaxis.set_label_text('mean dB')\n",
    "fig.set_title('Time Series for Chosen Subset')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 4. Create Seasonal Subsets of Time Series Records --- <font color='rgba(200,0,0,0.2)'> [Assignment Inside]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Let's expand upon SAR time series analysis. Often it is desirable to subset time series by season or months to compare data acquired under similar weather/growth/vegetation cover conditions. For example, in analyzing C-Band backscatter data, it might be useful to limit comparative analysis to dry season observations only as soil moisture might confuse signals during the wet seasons. To subset time series along the time axis we will make use of the following <i>Pandas</i> datatime index tools:\n",
    "<ul>\n",
    "    <li>month</li>\n",
    "    <li>day of year</li> \n",
    "</ul>\n",
    "<br>\n",
    "<b>Extract a hectare-sized area around our subset location (5,20,5,5):</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset = (5, 20, 5, 5)\n",
    "time_series_1 = timeSeries(raster_stack_pwr, time_index, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Convert the time series to a pandas DataFrame</b> to allow for more processing options.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(time_series_1, index=ts.index, columns=['g0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Label the data value column as 'g0' for $\\gamma^0$ and plot the time series backscatter profile:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ylim = (-15, -5)\n",
    "data_frame.plot(figsize=(16, 4))\n",
    "plt.title('Sentinel-1 C-VV Time Series Backscatter Profile, Subset: 5,20,5,5  ')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.ylim(ylim)\n",
    "_ = plt.legend([\"C-VV Time Series\"])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.1 Change Start Date of Time Series to November 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the cropped time series and save it as a png (time_series_backscatter_profile.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_sub1 = data_frame[data_frame.index>'2015-11-01']\n",
    "\n",
    "# Plot\n",
    "data_frame_sub1.plot(figsize=(16, 4))\n",
    "plt.title('Sentinel-1 C-VV Time Series Backscatter Profile, Subset: {}'.format(subset))\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.ylim(ylim)\n",
    "_ = plt.legend([\"C-VV Time Series\"])\n",
    "plt.grid()\n",
    "plt.savefig('time_series_backscatter_profile', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.2 Subset Time Series by Months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">Using the Pandas <i>DateTimeIndex</i> object index.month and numpy's logical_and function, we can subset the time series by month:\n",
    "<br><br>\n",
    "<b>Create subset ```data_frames```. In one, replace the data from June-February with NaNs. In the other, replace the data from March-May with NaNs:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_sub2 = deepcopy(data_frame_sub1)\n",
    "for index, row in data_frame_sub2.iterrows():\n",
    "    if index.month < 3 or index.month > 5:\n",
    "        row['g0'] = np.nan\n",
    "        \n",
    "data_frame_sub3 = deepcopy(data_frame_sub1)\n",
    "for index, row in data_frame_sub3.iterrows():\n",
    "    if index.month > 2 and index.month < 6:\n",
    "        row['g0'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the time series backscatter profile for March - May. Save the plot as a png (march2may_time_series_backscatter_profile.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "data_frame_sub2.plot(ax=ax)\n",
    "plt.title(f'Sentinel-1 C-VV Time Series Backscatter Profile, Subset: {subset}')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.ylim(ylim)\n",
    "_ = plt.legend([\"C-VV Time Series (March - May)\"], loc='best')\n",
    "plt.grid()\n",
    "plt.savefig('march2may_time_series_backscatter_profile', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> <b>Plot the time series backscatter profile for June - Feburary. Save the plot as a png (june2feb_time_series_backscatter_profile.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "data_frame_sub3.plot(ax=ax)\n",
    "plt.title(f'Sentinel-1 C-VV Time Series Backscatter Profile, Subset: {subset}')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.ylim(ylim)\n",
    "_ = plt.legend([\"C-VV Time Series (June-February)\"], loc='best')\n",
    "plt.grid()\n",
    "plt.savefig('june2feb_time_series_backscatter_profile', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.3 Split Time Series by Year to Compare Year-to-Year Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Sometimes it is useful to compare year-to-year $\\sigma^0$ values to identify changes in backscatter characteristics. This helps to distinguish true change from seasonal variability.\n",
    "<br><br>\n",
    "    <b>Split the time series into different years:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_frame_by_year = data_frame_sub1.groupby(pd.Grouper(freq=\"Y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the split time series. Save the plot as a png (yearly_time_series_backscatter_profile.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "for label, df in data_frame_by_year:\n",
    "    df.g0.plot(ax=ax, label=label.year)\n",
    "plt.legend()\n",
    "# data_frame_by_year.plot(ax=ax)\n",
    "plt.title('Sentinel-1 C-VV Time Series Backscatter Profile, Subset: {}'.format(subset))\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.ylim(ylim)\n",
    "plt.grid()\n",
    "plt.savefig('yearly_time_series_backscatter_profile', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 4.4 Create a Pivot Table to Group Years and Sort Data for Plotting Overlapping Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Pivot Tables are  a technique in data processing. They enable a person to arrange and rearrange (or \"pivot\") statistics in order to draw attention to useful information. To do so, we first <b>add columns for day-of-year and year to the data frame:</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add day of year\n",
    "data_frame_sub1 = data_frame_sub1.assign(doy=data_frame_sub1.index.dayofyear)\n",
    "# Add year\n",
    "data_frame_sub1 = data_frame_sub1.assign(year=data_frame_sub1.index.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create a pivot table which has day-of-year as the index and years as columns:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_table = pd.pivot_table(data_frame_sub1, index=['doy'], columns=['year'], values=['g0'])\n",
    "# Set the names for the column indices\n",
    "pivot_table.columns.set_names(['g0', 'year'], inplace=True) \n",
    "print(pivot_table.head(10))\n",
    "print('...\\n',pivot_table.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> As we can see, there are NaN values on the days in a year where no acquisition took place. Now we use time weighted interpolation to fill the dates for all the observations in any given year. For **time weighted interpolation** to work we need to create a dummy year as a date index, perform the interpolation, and reset the index to the day of year.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a dummy year as a date index:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add fake dates for year 100 to enable time sensitive interpolation \n",
    "# of missing values in the pivot table\n",
    "year_doy = ['2100-{}'.format(x) for x in pivot_table.index]\n",
    "y100_doy=pd.DatetimeIndex(pd.to_datetime(year_doy,format='%Y-%j'))\n",
    "\n",
    "# make a copy of the piv table and add two columns\n",
    "pivot_table_2 = pivot_table.copy()\n",
    "pivot_table_2 = pivot_table_2.assign(d100=y100_doy) # add the fake year dates\n",
    "pivot_table_2 = pivot_table_2.assign(doy=pivot_table_2.index) # add doy as a column to replace as index later again\n",
    "\n",
    "# Set the index to the dummy year\n",
    "pivot_table_2.set_index('d100', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Perform the time-weighted interpolation:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_table_2 = pivot_table_2.interpolate(method='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Reset the index to the day of year:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_table_2.set_index('doy', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Inspect the new pivot table and see whether we interpolated the NaN values where it made sense:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(pivot_table_2.head(10))\n",
    "print('...\\n',pivot_table_2.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the time series data with overlapping years. Save the plot as a png (overlapping_years_time_series_backscatter_profile.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_table_2.plot(figsize=(16, 8))\n",
    "plt.title('Sentinel-1 C-VV Time Series Backscatter Profile,\\\n",
    "Subset: 5,20,5,5  ')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.xlabel('Day of Year')\n",
    "_ = plt.ylim(ylim)\n",
    "plt.grid()\n",
    "plt.savefig('overlapping_years_time_series_backscatter_profile', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>ASSIGNMENT #2</u>:  </font> Interpret the Year-to-Year Time Series Plot</b> <font color='rgba(200,0,0,0.2)'> -- [4 Points] </font> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Answer the following questions related to the year-to-year time series plot shown above:\n",
    "<Ol>\n",
    "    <li>Describe the $\\gamma^0$ time series for year 2016. What kind of seasonal patterns do you see? Based on the observed seasonal patterns, what type of surface cover do you think was present at this area in 2016? <font color='rgba(200,0,0,0.2)'> -- [2 Points] </font></li><br>\n",
    "    <li>Describe the $\\gamma^0$ time series for year 2017. What kind of seasonal patterns do you see and how do they differ from the previous year? <font color='rgba(200,0,0,0.2)'> -- [2 Points] </font></li><br>\n",
    "</Ol>\n",
    "<br>\n",
    "\n",
    "PROVIDE YOUR ANSWERS BELOW:\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 5. Time Series Change Detection --- <font color='rgba(200,0,0,0.2)'> [Assignment Inside]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Now we are ready to perform efficient change detection on the time series data. We will discuss two approaches:\n",
    "<ol>\n",
    "    <li>Year-to-year differencing of the subsetted time series</li>\n",
    "    <li>Cumulative Sum-based change detection</li>\n",
    "</ol>\n",
    "</font> \n",
    "<br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Set a dB change threshold.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "threshold = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the difference between years (2016 and 2017):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff_2017_2016 = pivot_table_2.g0[2017] - pivot_table_2.g0[2016]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.1 Change Detection based on Year-to-Year Differencing  --- <font color='rgba(200,0,0,0.2)'> [Assignment Inside]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Compute and plot the differences between the interpolated time series and look for change using a threshold value. Save the plot as a png (year2year_differencing_time_series.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = diff_2017_2016.plot(kind='line', figsize=(16,8))\n",
    "plt.title('Year-to-Year Difference Time Series')\n",
    "plt.ylabel('$\\Delta\\gamma^o$ [dB]')\n",
    "plt.xlabel('Day of Year')\n",
    "plt.grid()\n",
    "plt.savefig('year2year_differencing_time_series', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the days-of-year on which the threshold was exceeded:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "threshold_exceeded = diff_2017_2016[abs(diff_2017_2016) > threshold]\n",
    "threshold_exceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> From the <i>threshold_exceeded</i> dataframe we can infer the first date at which the threshold was exceeded. We would label this date as a **change point**. As an additional criteria for labeling a change point, one can also consider the number of observations after an identified change point that also excided the threshold. If only one or two observations differed from the year before this could be considered an outlier. Additional smoothing of the time series may sometimes be useful to avoid false detections. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-danger\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>ASSIGNMENT #3</u>:  </font> Perform Year-to-Year Differencing-based Change Detection for a Different Subset</b> <font color='rgba(200,0,0,0.2)'> -- [5 Points] </font> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Go back to the beginning of Section 4 and change the subset coordinates to a different subset (i.e., modify to <i>subset=($X$,$Y$,5,5)</i> with $X$ and $Y$ being the center of your modified subset). Work through the workbook from the beginning of Section 4 until the end of Section 5.1 with your modified subset. Discuss whether or not your new subset shows change according to the 3dB change threshold.\n",
    "<br><br>\n",
    "\n",
    "DISCUSS BELOW WHETHER YOUR NEW SUBSET SHOWS CHANGE:\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 5.2 Cumulative Sums for Change Detection --- <font color='rgba(200,0,0,0.2)'> [Assignment Inside]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> Another approach to detect change in regularly acquired data is employing the method of **cumulative sums**. Changes are determined by comparing the time series data against its mean. A full explanation and examples from the financial sector can be found at [http://www.variation.com/cpa/tech/changepoint.html](http://www.variation.com/cpa/tech/changepoint.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.A First let's Consider a Time Series and it's Mean Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">We look at two full years of observations from Sentinel-1 data for an area where we suspect change. In the following, we define $X$ as our time series\n",
    "<br><br>\n",
    "\\begin{equation}\n",
    "X = (X_1,X_2,...,X_n)\n",
    "\\end{equation}\n",
    "\n",
    "with $X_i$ being the SAR backscatter values at times $i=1,...,n$ and $n$ is the number of observations in the time series.\n",
    "<br><br>\n",
    "<b>Create a times series of the subset and calculate the backscatter values:</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subset = (5, 20, 3, 3)\n",
    "#subset=(12,5,3,3)\n",
    "time_series_1 = timeSeries(raster_stack_pwr, time_index, subset)\n",
    "backscatter_values = time_series_1[time_series_1.index>'2015-10-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.B Filtering the Time Series for Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> It is advantageous in noisy SAR time series like those from C-Band Sentinel-1 data to reduce noise by <b>applying a filter along the time axis</b>. Pandas offers a <i>\"rolling\"</i> function for these purposes. Using the <i>rolling</i> function, we will apply a <i>median filter</i> to our data.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the median backscatter values and plot them against the original values. Save the plot as a png (Original vs. Median Time Series):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backscatter_values_median = backscatter_values.rolling(5, center=True).median()\n",
    "backscatter_values_median.plot(figsize=(16, 4))\n",
    "_ = backscatter_values.plot()\n",
    "plt.title('Original vs. Median Time Series')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig('original_vs_median_time_series', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the time series' mean value and plot it against the original values. Save the plot as a png (original_time_series_vs_mean_val.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "backscatter_values.plot()\n",
    "plt.title('Original Time Series vs. Mean Value')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "ax.axhline(backscatter_values.mean(), color='red')\n",
    "_ = plt.legend(['$\\gamma^o$', '$\\overline{\\gamma^o}$'])\n",
    "plt.grid()\n",
    "plt.savefig('original_time_series_vs_mean_val', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the time series' mean value and plot it against the median values. Save the plot as a png (median_time_series_vs_mean_val.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backscatter_values_mean = backscatter_values.mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 4))\n",
    "backscatter_values_median.plot()\n",
    "plt.title('Median Time Series vs. Mean Value')\n",
    "plt.ylabel('$\\gamma^o$ [dB]')\n",
    "ax.axhline(backscatter_values.mean(), color='red')\n",
    "_ = plt.legend(['$\\gamma^o$', '$\\overline{\\gamma^o}$'])\n",
    "plt.grid()\n",
    "plt.savefig('median_time_series_vs_mean_val', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.C Calculate the Residuals of the Time Series Against the Mean $\\overline{\\gamma^o}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">To get to the residual, we calculate \n",
    "\n",
    "\\begin{equation}\n",
    "R = X_i - \\overline{X}\n",
    "\\end{equation}</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the residuals:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "residuals = backscatter_values - backscatter_values_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.D Calculate Cumulative Sum of the Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The cumulative sum is defined as: \n",
    "\n",
    "\\begin{equation}\n",
    "S = \\displaystyle\\sum_1^n{R_i}\n",
    "\\end{equation}</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"> <b>Calculate and plot the cumulative sum of the residuals. Save the plot as a png (cumulative_sum_residuals.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sums = residuals.cumsum()\n",
    "\n",
    "_ = sums.plot(figsize=(16, 6))\n",
    "plt.title('Cumulative Sum of the Residuals')\n",
    "plt.ylabel('Cummulative Sum $S$ [dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig('cumulative_sum_residuals', dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> The **cumulative sum** is a good indicator of change in the time series. An estimator for the magnitude of change is given as the difference between the maximum and minimum value of the cumulative sum $S$: \n",
    "\n",
    "\\begin{equation}\n",
    "S_{DIFF} = S_{MAX} - S_{MIN}\n",
    "\\end{equation}\n",
    "<br><br>\n",
    "<b>Calculate the magnitude of change:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_mag = sums.max() - sums.min()\n",
    "print('Change magnitude: %5.3f dB' % (change_mag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.E Identify Change Point in the Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> A candidate change point is identified from $S$ at the time where $S_{MAX}$ is found:\n",
    "\n",
    "\\begin{equation}\n",
    "T_{{CP}_{before}} = T(S_i = S_{MAX})\n",
    "\\end{equation}\n",
    "\n",
    "with $T_{{CP}_{before}}$ being the timestamp of the last observation <i>before</i> the identified change point, $S_i$ is the cumulative sum of $R$ with $i=1,...n$, and $n$ is the number of observations in the time series. \n",
    "\n",
    "The first observation <i>after</i> a change occurred ($T_{{CP}_{after}}$) is then found as the first observation in the time series following $T_{{CP}_{before}}$.\n",
    "<br><br>\n",
    "<b>Calculate $T_{{CP}_{before}}$:</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_before = sums[sums==sums.max()].index[0]\n",
    "print('Last date before change occurred: {}'.format(change_point_before.date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate $T_{{CP}_{after}}$:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_after = sums[sums.index > change_point_before].index[0]\n",
    "print('First date after change occurred: {}'.format(change_point_after.date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.F Determine our Confidence in the Identified Change Point using Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">We can determine if an identified change point is indeed a valid detection by <b>randomly reordering the time series</b> and <b>comparing the various $S$ curves</b>. During this <b>\"bootstrapping\"</b> approach, we count how many times the $S_{DIFF}$ values are greater than $S_{{DIFF}_{random}}$ of the identified change point. \n",
    "    \n",
    "After bootstrapping, we define the <b>confidence level $CL$</b> in a detected change point according to:\n",
    "\n",
    "\\begin{equation}\n",
    "CL = \\frac{N_{GT}}{N_{bootstraps}}\n",
    "\\end{equation}\n",
    "\n",
    "where $N_{GT}$ is the number of times $S_{DIFF}$ > $S_{{DIFF}_{random}}$ and $N_{bootstraps}$ is the number of bootstraps randomizing $R$.\n",
    "<br><br><br>\n",
    "As another quality metric we can also calculate the <b>significance $CP_{significance}$</b> of a change point according to: \n",
    "\n",
    "\\begin{equation}\n",
    "CP_{significance} = 1 - \\left( \\frac{\\sum_{b=1}^{N_{bootstraps}}{S_{{DIFF}_{{random}_i}}}}{N_{bootstraps}} \\middle/ S_{DIFF} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "The closer $CP_{significance}$ is to 1, the more significant the change point.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Write a function that implements the bootstrapping algorithm:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pyplot must be imported as plt\n",
    "import random\n",
    "def bootstrap(n_bootstraps, sums, residuals, output_file=False):\n",
    "    fig, ax = plt.subplots(figsize=(16,6))\n",
    "    ax.set_ylabel('Cumulative Sums of the Residuals')\n",
    "    change_mag_random_sum = 0\n",
    "    change_mag_random_max = 0 # to keep track of the maximum change magnitude of the bootstrapped sample\n",
    "    qty_change_mag_above_random = 0 # to keep track of the maxium Sdiff of the bootstrapped sample\n",
    "    print(\"Running Bootstrapping for %4.1f iterations ...\" % (n_bootstraps))\n",
    "    colors = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'c', 'm', 'y', 'k', 'g']\n",
    "    for i in range(n_bootstraps):\n",
    "        residuals_random = residuals.sample(frac=1)  # Randomize the time steps of the residuals\n",
    "        sums_random = residuals_random.cumsum()\n",
    "        change_mag_random = sums_random.max() - sums_random.min()\n",
    "        change_mag_random_sum += change_mag_random\n",
    "        if change_mag_random > change_mag_random_max:\n",
    "            change_mag_random_max = change_mag_random\n",
    "        if change_mag > change_mag_random:\n",
    "            qty_change_mag_above_random += 1\n",
    "        sums_random.plot(ax=ax, color=random.choice(colors), label='_nolegend_')\n",
    "        if ((i+1)/n_bootstraps*100) % 10 == 0:\n",
    "            print(\"\\r%4.1f percent completed ...\" % ((i+1)/n_bootstraps*100), end='\\r', flush=True)\n",
    "    sums.plot(ax=ax, color='r', linewidth=3)\n",
    "    fig.legend(['S Curve for Candidate Change Point'])\n",
    "    print(f\"Bootstrapping Complete\")\n",
    "    _ = ax.axhline(change_mag_random_sum/n_bootstraps, color='b')\n",
    "    plt.grid()\n",
    "    if output_file:\n",
    "        plt.savefig(f\"bootstrap_{n_bootstraps}\", dpi=72)\n",
    "        print(f\"Saved plot: bootstrap_{n_bootstraps}.png\")\n",
    "    return [qty_change_mag_above_random, change_mag_random_sum]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Call the bootstrap function with a sample size of 2000:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_bootstraps = 2000\n",
    "bootstrapped_change_mag = bootstrap(n_bootstraps, sums, residuals, output_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\"> Based on the bootstrapping results, we can now calculate <b>Confidence Level $CL$</b> and <b>Significance $CP_{significance}$</b> for our candidate change point.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the confidence level:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confidence_level = 1.0 * bootstrapped_change_mag[0] / n_bootstraps\n",
    "print('Confidence Level for change point {} percent'.format(confidence_level*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the change point significance:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_significance = 1.0 - (bootstrapped_change_mag[1]/n_bootstraps)/change_mag \n",
    "print('Change point significance metric: {}'.format(change_point_significance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 5.2.G TRICK: Detrending of Time Series Before Change Detection to Improve Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> De-trending the time series with global image means can improve the robustness of change point detection as global image time series anomalies stemming from calibration or seasonal trends are removed prior to time series analysis. This de-trending needs to be performed with large subsets so real change is not influencing the image statistics. \n",
    "\n",
    "NOTE: Due to the small size of our subset, we will see some distortions when we detrend the time series.\n",
    "\n",
    "<b>Let's start by building a global image means time series and plot the global means. Save the plot as a png (global_means_time_series.png):</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "means_pwr = np.mean(raster_stack_pwr, axis=(1, 2))\n",
    "means_dB = 10.0 * np.log10(means_pwr)\n",
    "global_means_ts = pd.Series(means_dB, index=time_index)\n",
    "global_means_ts = global_means_ts[global_means_ts.index > '2015-10-31'] # filter dates\n",
    "global_means_ts = global_means_ts.rolling(5, center=True).median()\n",
    "global_means_ts.plot(figsize=(16, 6))\n",
    "plt.title('Time Series of Global Means')\n",
    "plt.ylabel('[dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig(f\"global_means_time_series\", dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Compare the time series of global means (above) to the time series of our small subset (below):</b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backscatter_values.plot(figsize=(16, 6))\n",
    "plt.title('Sentinel-1 C-VV Time Series Backscatter Profile,\\\n",
    "Subset: 5,20,5,5  ')\n",
    "plt.ylabel('[dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> There are some signatures of the global seasonal trend in our subset time series. To remove these signatures and get a cleaner time series of change, we subtract the global mean time series from our subset time series.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>De-trend the subset and re-plot the backscatter profile. Save the plot (detrended_time_series.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backscatter_minus_seasonal = backscatter_values - global_means_ts\n",
    "backscatter_minus_seasonal.plot(figsize=(16, 6))\n",
    "plt.title('De-trended Sentinel-1 C-VV Time Series Backscatter Profile, Subset: 5,20,5,5')\n",
    "plt.ylabel('[dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig(f\"detrended_time_series\", dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save a plot comparing the original, global means, and detrended time-series (globalMeans_original_detrended_time_series.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "means_pwr = np.mean(raster_stack_pwr, axis=(1, 2))\n",
    "means_dB = 10.0 * np.log10(means_pwr)\n",
    "global_means_ts = pd.Series(means_dB, index=time_index)\n",
    "global_means_ts = global_means_ts[global_means_ts.index > '2015-10-31'] # filter dates\n",
    "global_means_ts = global_means_ts.rolling(5, center=True).median()\n",
    "global_means_ts.plot(figsize=(16, 6))\n",
    "backscatter_values.plot(figsize=(16, 6))\n",
    "backscatter_minus_seasonal = (backscatter_values - global_means_ts)\n",
    "backscatter_minus_seasonal.plot(figsize=(16, 6))\n",
    "plt.title('Time Series of Global Means')\n",
    "plt.ylabel('[dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig(f\"globalMeans_original_detrended_time_series\", dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Recalculate the residuals based on the de-trended data:</b> and plot it:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backscatter_values_mean = backscatter_minus_seasonal.mean()\n",
    "residuals = backscatter_minus_seasonal - backscatter_values_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Compute, plot, and save the cumulative sum of the detrended time series (cumualtive_sum_detrended_time_series.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sums = residuals.cumsum()\n",
    "_ = sums.plot(figsize=(16, 6))\n",
    "plt.title(\"Cumulative Sum of the Detrended Time Series\")\n",
    "plt.ylabel('CumSum $S$ [dB]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "plt.savefig(f\"cumualtive_sum_detrended_time_series\", dpi=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Detect Change Point and extract related change dates:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_before = sums[sums==sums.max()].index[0]\n",
    "print('Last date before change occurred: {}'.format(change_point_before.date()))\n",
    "\n",
    "change_point_after = sums[sums.index > change_point_before].index[0]\n",
    "print('First date after change occurred: {}'.format(change_point_after.date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Perform bootstrapping:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_bootstraps = 2000\n",
    "bootstrapped_change_mag = bootstrap(n_bootstraps, sums, residuals, output_file=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the confidence level:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confidence_level = bootstrapped_change_mag[0] / n_bootstraps\n",
    "print('Confidence Level for change point {} percent'.format(confidence_level*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>\n",
    "<font face=\"Calibri\" size=\"3\">Note how the <b>change point significance $CP_{significance}$</b> has increased in the detrended time series:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_significance = 1.0 - (bootstrapped_change_mag[1]/n_bootstraps) / change_mag \n",
    "print('Change point significance metric: {}'.format(change_point_significance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<hr>\n",
    "<div class=\"alert alert-danger\">\n",
    "<font face=\"Calibri\" size=\"5\"> <b> <font color='rgba(200,0,0,0.2)'> <u>ASSIGNMENT #4</u>:  </font> Perform Cumulative Sum-based Change Detection for a Different Subset</b> <font color='rgba(200,0,0,0.2)'> -- [6 Points] </font> </font>\n",
    "\n",
    "<font face=\"Calibri\" size=\"3\"> Go back to the beginning of Section 5.2 and change the subset coordinates to a different subset (i.e., modify to <i>subset=($X$,$Y$,5,5)</i> with $X$ and $Y$ being the center of your selected subset). Work through the workbook from the beginning to the end of Section 5.2with your selected subset. Discuss whether or not your new subset shows change according to the <i>Cumulative Sum</i> approach.\n",
    "<br><br>\n",
    "\n",
    "DISCUSS BELOW WHETHER YOUR NEW SUBSET SHOWS CHANGE:\n",
    "\n",
    "</font>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 6. Cumulative Sum-based Change Detection Across an Entire Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> With numpy arrays we can apply the concept of **cumulative sum change detection** analysis effectively on the entire image stack. We take advantage of array slicing and axis-based computing in numpy. Axis 0 is the time domain in our raster stacks.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.1 We Create Time Series Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Filter out the first layer (Dates >= '2015-11-1'):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raster_stack = raster_stack_pwr\n",
    "raster_stack_sub = raster_stack_pwr[1:, :, :]\n",
    "time_index_sub = time_index[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font size=\"3\"><b>Uncomment the following code cell <u>if</u> you wish to change to dB scale:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# raster_stack = 10.0 * np.log10(raster_stack_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font size=\"3\"><b>Plot and save Band-1 (band_1.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "band_number = 0\n",
    "vmin = np.percentile(raster_stack[band_number], 5)\n",
    "vmax = np.percentile(raster_stack[band_number], 95)\n",
    "plt.title('Band  {} {}'.format(band_number+1, time_index_sub[band_number].date()))\n",
    "plt.imshow(raster_stack[0], cmap='gray', vmin=vmin, vmax=vmax)\n",
    "_ = plt.colorbar()\n",
    "plt.savefig('band_1.png', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font size=\"3\"><b>Save the plot as a GeoTiff (band_1.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(raster_stack[0], 'band_1', coords, utm_zone, cmap='gray', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.2 Calculate Mean Across Time to Prepare for Calculation of Cumulative Sum $S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"> <b>Plot and save the the raster stack mean (raster_stack_mean.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raster_stack_mean = np.mean(raster_stack, axis=0)\n",
    "vmin = np.nanpercentile(raster_stack_mean, 2)\n",
    "vmax = np.nanpercentile(raster_stack_mean, 98)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(raster_stack_mean, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "_ = plt.colorbar()\n",
    "plt.savefig('raster_stack_mean.png', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font size=\"3\"><b>Save the raster stack mean as a GeoTiff (raster_stack_mean.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(raster_stack_mean, 'raster_stack_mean', coords, utm_zone, cmap='gray', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Calculate the residuals:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "residuals = raster_stack - raster_stack_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Close img, as it is no longer needed in the notebook:</b></font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raster_stack = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot and save the residuals for band 1 (residuals_band_1.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vmin = np.nanpercentile(residuals[0], 1)\n",
    "vmax = np.nanpercentile(residuals[0], 99)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(residuals[0], cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "plt.title('Residuals for Band  {} {}'.format(band_number+1, time_index_sub[band_number].date()))\n",
    "_ = plt.colorbar()\n",
    "plt.savefig('residuals_band_1', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the residuals for band 1 as a GeoTiff (residuals_band_1.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(residuals[0], 'residuals_band_1', coords, utm_zone, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.3 Calculate Cumulative Sum $S$ as well as Change Magnitude $S_{diff}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot and save the cumulative sum max, min, and change magnitude (Smax_Smin_Sdiff.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sums = np.cumsum(residuals, axis=0)\n",
    "sums_max = np.max(sums, axis=0)\n",
    "sums_min = np.min(sums, axis=0)\n",
    "change_mag = sums_max - sums_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = sums_min.min()\n",
    "vmax = sums_max.max()\n",
    "sums_max_plot = ax[0].imshow(sums_max, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('$S_{max}$')\n",
    "ax[1].imshow(sums_min, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('$S_{min}$')\n",
    "ax[2].imshow(change_mag, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[2].set_title('Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "_ = fig.colorbar(sums_max_plot, cax=cbar_ax)\n",
    "plt.savefig('Smax_Smin_Sdiff', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save $S_{max}$, $S_{min}$, and change magnitude $|S|$ as a GeoTiff:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(sums_max, 'Smax', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(sums_min, 'Smin', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag, 'Sdiff', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.4 Mask $S_{diff}$ With a-priori Threshold To Idenfity Change Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">To identified change candidate pixels, we can threshold $S_{diff}$ to reduce computation of the bootstrapping. For land cover change we would not expect more than 5-10% change pixels in a landscape. So, if the test region is reasonably large, setting a threshold for expected change to 10% is appropriate. In our example we'll start out with a very conservative threshold of 20%.\n",
    "\n",
    "<b>Plot and save the histogram for the change magnitude and the change magnitude cumulative distribution function (Sdiff_histogram_CDF.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plt.figure(figsize=(14, 6)) # Initialize figure with a size\n",
    "ax1 = fig.add_subplot(121)  # 121 determines: 2 rows, 2 plots, first plot\n",
    "ax2 = fig.add_subplot(122)\n",
    "# Second plot: Histogram\n",
    "# IMPORTANT: To get a histogram, we first need to *flatten* \n",
    "# the two-dimensional image into a one-dimensional vector.\n",
    "histogram = ax1.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)))\n",
    "ax1.xaxis.set_label_text('Change Magnitude')\n",
    "ax1.set_title('Change Magnitude Histogram')\n",
    "plt.grid()\n",
    "n, bins, patches = ax2.hist(change_mag.flatten(), bins=200, range=(0, np.max(change_mag)), cumulative='True', density='True', histtype='step', label='Empirical')\n",
    "ax2.xaxis.set_label_text('Change Magnitude')\n",
    "ax2.set_title('Change Magnitude CDF')\n",
    "plt.grid()\n",
    "plt.savefig('Sdiff_histogram_CDF', dpi=72, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">Using this threshold, we can create a plot to <b>visualize our change candidate areas. Save the plot (change_candidate.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "precentile = 0.75\n",
    "out_indicies = np.where(n>precentile)\n",
    "threshold_indicies = np.min(out_indicies)\n",
    "threshold = bins[threshold_indicies]\n",
    "print('At the {}% percentile, the threshold value is {:2.2f}'.format(precentile*100,threshold))\n",
    "\n",
    "change_mag_mask = change_mag < threshold\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Change Candidate Areas (black)')\n",
    "_ = plt.imshow(change_mag_mask, cmap='gray')\n",
    "plt.savefig('change_candidate', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the change candidate plot as a GeoTiff (change_candidate.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag_mask, 'change_candidate', coords, utm_zone, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.5 Bootstrapping to Prepare for Change Point Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">We can now perform bootstrapping over the candidate pixels. The workflow is as follows:\n",
    "<ul>\n",
    "    <li>Filter our residuals to the change candidate pixels</li>\n",
    "    <li>Perform bootstrapping over candidate pixels</li>\n",
    "</ul>\n",
    "<br>\n",
    "<b>For efficient computing we <b>permutate the index of the time axis:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "residuals_mask = np.broadcast_to(change_mag_mask, residuals.shape)\n",
    "residuals_masked = np.ma.array(residuals, mask=residuals_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">On the masked time series stack of residuals, we can <b>re-compute the cumulative sums:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sums_masked = np.ma.cumsum(residuals_masked, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Plot the min sums, max sums, and change magnitude of the masked subset (masked_Smax_Smin_Sdiff.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sums_masked_max = np.ma.max(sums_masked, axis=0)\n",
    "sums_masked_min = np.ma.min(sums_masked, axis=0)\n",
    "change_mag = sums_masked_max - sums_masked_min\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4))\n",
    "vmin = sums_masked_min.min()\n",
    "vmax = sums_masked_max.max()\n",
    "sums_masked_max_plot = ax[0].imshow(sums_masked_max, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title('$S_{max}$')\n",
    "ax[1].imshow(sums_masked_min, cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "ax[1].set_title('$S_{min}$')\n",
    "ax[2].imshow(change_mag, vmin=vmin, cmap=\"jet\", vmax=vmax)\n",
    "ax[2].set_title('Change Magnitude')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "_ = fig.colorbar(sums_masked_max_plot, cax=cbar_ax)\n",
    "plt.savefig('masked_Smax_Smin_Sdiff', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save $S_{max}$, $S_{min}$, and change magnitude $|S|$ as a GeoTiff:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(sums_masked_max, 'masked_Smax', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(sums_masked_min, 'masked_Smin', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_mag, 'masked_Sdiff', coords, utm_zone, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Perform bootstrapping:</b>:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "residuals_random = residuals_masked[random_index,:,:]\n",
    "n_bootstraps = 2000  # bootstrap sample size\n",
    "# to keep track of the maxium Sdiff of the bootstrapped sample:\n",
    "change_mag_random_max = np.ma.copy(change_mag) \n",
    "change_mag_random_max[~change_mag_random_max.mask] = 0\n",
    "# to compute the Sdiff sums of the bootstrapped sample:\n",
    "change_mag_random_sum = np.ma.copy(change_mag) \n",
    "change_mag_random_sum[~change_mag_random_max.mask] = 0\n",
    "change_mag_random_sum = np.zeros_like(change_mag)\n",
    "# to keep track of the count of the bootstrapped sample\n",
    "qty_change_mag_above_random = change_mag_random_sum\n",
    "qty_change_mag_above_random[~qty_change_mag_above_random.mask] = 0\n",
    "print(np.max(qty_change_mag_above_random))\n",
    "print(\"Running Bootstrapping for %4.1f iterations ...\" % (n_bootstraps))\n",
    "for i in range(n_bootstraps):\n",
    "    # For efficiency, we shuffle the time axis index and use that \n",
    "    #to randomize the masked array\n",
    "    random_index = np.random.permutation(residuals_masked.shape[0])\n",
    "    # Randomize the time step of the residuals\n",
    "    residuals_random = residuals_masked[random_index, :, :]  \n",
    "    sums_random = np.ma.cumsum(residuals_random, axis=0)\n",
    "    sums_random_max = np.ma.max(sums_random, axis=0)\n",
    "    sums_random_min = np.ma.min(sums_random, axis=0)\n",
    "    change_mag_random = sums_random_max - sums_random_min\n",
    "    change_mag_random_sum += change_mag_random\n",
    "    change_mag_random_max[np.ma.greater(change_mag_random, change_mag_random_max)] = \\\n",
    "    change_mag_random[np.ma.greater(change_mag_random, change_mag_random_max)]\n",
    "    qty_change_mag_above_random[np.ma.greater(change_mag, change_mag_random)] += 1\n",
    "    if ((i+1)/n_bootstraps*100)%10 == 0:\n",
    "        print(\"\\r%4.1f percent completed ...\" % ((i+1)/n_bootstraps*100), end='\\r', flush=True)\n",
    "print(f\"Bootstrapping Complete.      \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.6 Extract Confidence Metrics and Select Final Change Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">We first <b>compute for all pixels the confidence level $CL$, the change point significance metric $CP_{significance}$ and the product of the two as our confidence metric for identified change points. Plot and save them (confidence_change_point.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "confidence_level = qty_change_mag_above_random / n_bootstraps\n",
    "change_point_significance = 1.0 - (change_mag_random_sum/n_bootstraps) / change_mag \n",
    "#Plot\n",
    "fig, ax = plt.subplots(1, 3 ,figsize=(16, 4))\n",
    "a = ax[0].imshow(confidence_level*100, cmap=\"jet\")\n",
    "fig.colorbar(a, ax=ax[0])\n",
    "ax[0].set_title('Confidence Level %')\n",
    "a = ax[1].imshow(change_point_significance, cmap=\"jet\")\n",
    "fig.colorbar(a, ax=ax[1])\n",
    "ax[1].set_title('Change Point Significance')\n",
    "a = ax[2].imshow(confidence_level*change_point_significance, cmap=\"jet\")\n",
    "fig.colorbar(a, ax=ax[2])\n",
    "_ = ax[2].set_title('Confidence Level\\nx\\nChange Point Significance')\n",
    "plt.savefig('confidence_change_point', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the confidence level of the masked subset as a GeoTiff (confidence_level.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*100, 'confidence_level', coords, utm_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the change point significance of the masked subset as a GeoTiff (change_point.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_point_significance, 'change_point', coords, utm_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the confidence level x change point significance of the masked subset as a GeoTiff (CL_x_CP.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*change_point_significance, 'CL_x_CP', coords, utm_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Set a change point threshold of 0.5:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_threshold = -1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Create and save a plot showing the final change points (change_point_thresh.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.title('Detected Change Pixels based on Threshold %2.1f' % (change_point_threshold))\n",
    "a = ax.imshow(confidence_level*change_point_significance < change_point_threshold, cmap='cool')\n",
    "plt.savefig('change_point_thresh', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the thresholded change point significance of the masked subset as a GeoTiff (change_point_thresh.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(confidence_level*change_point_significance < change_point_threshold, 'change_point_thresh', coords, utm_zone, cmap='cool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 6.7 Derive Timing of Change for Each Change Pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">Our last step in the identification of the change points is to extract the timing of the change. We will produce a raster layer that shows the band number of the first date after a change was detected. We will make use of the numpy indexing scheme.</font>\n",
    "<br><br>\n",
    "<font face=\"Calibri\" size=\"3\"><b>Create a combined mask of the first threshold and the identified change points after the bootstrapping:</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make a mask of our change points from the new threhold and the previous mask\n",
    "change_point_mask = np.ma.mask_or(confidence_level*change_point_significance<change_point_threshold, \n",
    "                                  confidence_level.mask)\n",
    "# Broadcast the mask to the shape of the masked S curves\n",
    "change_point_mask2 = np.broadcast_to(change_point_mask, sums_masked.shape)\n",
    "# Make a numpy masked array with this mask\n",
    "change_point_raster = np.ma.array(sums_masked.data, mask=change_point_mask2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">To retrieve the dates of the change points we <b>find the band indices in the time series along the time axis where the maximum of the cumulative sums was located.</b> Numpy offers the \"argmax\" function for this purpose.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "change_point_index = np.ma.argmax(change_point_raster, axis=0)\n",
    "change_indices = list(np.unique(change_point_index))\n",
    "change_indices.remove(0)\n",
    "print(f\"Change Indicies:\\n{change_indices}\")\n",
    "# Look up the dates from the indices to get the change dates\n",
    "all_dates = time_index[time_index>'2015-10-31']\n",
    "change_dates = [str(all_dates[x].date()) for x in change_indices]\n",
    "print(f\"\\nChange Dates:\\n{change_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\">Lastly, we <b>plot and the change dates using the change point index raster and labeling the change dates (change_dates.png):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ticks = change_indices\n",
    "tick_labels = change_dates\n",
    "\n",
    "cmap = plt.cm.get_cmap('tab20c',ticks[-1])\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "cax = ax.imshow(change_point_index, interpolation='nearest', cmap=cmap)\n",
    "# fig.subplots_adjust(right=0.8)\n",
    "# cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "# fig.colorbar(p,cax=cbar_ax)\n",
    "\n",
    "ax.set_title('Dates of Change')\n",
    "# cbar = fig.colorbar(cax, ticks=ticks)\n",
    "cbar = fig.colorbar(cax, ticks=ticks, orientation='horizontal')\n",
    "_ = cbar.ax.set_xticklabels(tick_labels, size=10, rotation=45, ha='right')\n",
    "plt.savefig('change_dates', dpi=300, transparent='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"3\"><b>Save the dates of change plot as a GeoTiff (change_dates.tiff):</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "geotiff_from_plot(change_point_index, 'change_dates', coords, utm_zone, interpolation='nearest', cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>GEOS 657 Microwave Remote Sensing - Version 1.3.0 - November 2021\n",
    "    <br>\n",
    "        <b>Version Changes:</b>\n",
    "    <ul>\n",
    "        <li>url_widget</li>\n",
    "        <li>remove depreciated asf_notebook functions</li>\n",
    "    </ul>\n",
    "    </i>\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtc_analysis",
   "language": "python",
   "name": "conda-env-.local-rtc_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
